---
title: "Getting Started" 
author: "<h4>Authors: <i>`r auths <- eval(parse(text = gsub('person','c',read.dcf('../DESCRIPTION', fields = 'Authors@R'))));paste(auths[names(auths)=='given'],auths[names(auths)=='family'], collapse = ', ')`</i></h4>" 
date: "<h4>Vignette updated: <i>`r format( Sys.Date(), '%b-%d-%Y')`</i></h4>"
output:
  BiocStyle::html_document
vignette: >
    %\VignetteIndexEntry{templateR} 
    %\usepackage[utf8]{inputenc}
    %\VignetteEngine{knitr::rmarkdown}
---


```{r, echo=FALSE, include=FALSE}
pkg <- read.dcf("../DESCRIPTION", fields = "Package")[1]
library(pkg, character.only = TRUE)
```


```R
library(`r pkg`)
```

# Import peaks

## Pre-computed peaks

Some peaks files are already made available on [GEO](https://www.ncbi.nlm.nih.gov/geo/). 
`import_peaks` will import these as a named list `GenomicRanges`, 
where the names are the GEO sample `ids`. 

```{r}
grl <- PeakyFinders::import_peaks(
    ids = "GSM945244",
    searches = construct_searches(keys = c("narrowpeak",
                                           "broadpeak"))) 
```


## Pre-computed peak: subset

By default, the genome-wide files are imported.
However, you can also query specific subset of these peak files
defined by `query_granges`. 

Here, we'll just construct query for all of chromosome 22 
using the helper function `get_genome`

```{r}
query_granges <- PeakyFinders::get_genome(genome = "hg19",
                                          keep.chr = 22)

grl2 <- PeakyFinders::import_peaks(
    ids = "GSM945244",
    searches = construct_searches(keys = c("narrowpeak",
                                           "broadpeak")),
    builds = "hg19",
    query_granges = query_granges,
    query_granges_build = "hg19") 

knitr::kable(
    head(grl2$GSM945244)
)
```

## Call peaks

When no pre-computed peaks are available, you can instead use `import_peaks` to recompute peaks from *bigWig* or *bedGraph* files.  

```{r}
grl3 <- PeakyFinders::import_peaks(
    ids = "GSM945244",
    searches = construct_searches(keys = "bigwig"),
    builds = "hg19",
    query_granges = query_granges,
    query_granges_build = "hg19"
    ) 

knitr::kable(
    head(grl3$GSM945244)
)
```
## Parallelization

To speed up the process of importing and/or calling peaks, 
you can take advantage of the parallelization features in `import_peaks`. 

For example, if you want to call peaks across the entire genome
from a given *bigWig* file, you could speed up this process by dividing the task by chromosome and distributing it across multiple cores or compute nodes. 

Internally, `PeakyFinders` takes a number of steps to optimise these parallel processes, so you don't have to worry about it as much. This helps to avoid common issues stemming from excessive numbers of queries, both to the servers where the peak data is hosted, and to the C libraries that R relies on to makes these queries.  

**Tip**:  

> It's usually a good idea to leave several cores free when running parallel processes, so that you can still have enough resources to use your computer while the function is running. In the example below, I'm using 10/12 cores on my local laptop. 

```{r, eval=FALSE}
grl4 <- PeakyFinders::import_peaks(
    ids = "GSM945244",
    searches = construct_searches(keys = "bigwig"),
    split_chromosomes = TRUE,
    nThread = 10
    )  
```


# Session Info 

<details> 

```{r Session Info}
utils::sessionInfo()
```

</details>  

<br>
